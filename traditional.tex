In this section, we describe common approaches that are traditionally
used at HPC sites to install scientific software and to deal with the
growing number of modules over the lifetime of an HPC system. We start
our discussion by module tools used by many sites followed by a brief
overview of the concept of module files and various module naming
schemes which are in use today.  Next, we review commonly used
workflows for installing scientific software and finally summarize the
shortcomings we have identified with these approaches.

\subsection{Environment modules system}

For software not installed in standard system locations a user's
\texttt{\$PATH} must be modified to include the directory to a software
package.  Other enviroment variables may also be required for this
software to operate for the user (e.g. \texttt{\$LD\_LIBRARY\_PATH}, ...).
One approach for each package to provide shell scripts for the user to
source to modify their environment.

The environment modules system provides a technique with several major
advantages. The first is that a single file provides a definitions
required for a user to access the package.  There is no need for a
separate file for each shell.  To access a particular software
``\emph{package}'', the user simply \emph{loads} a module:
{\small
\begin{alltt}
    \textbf{\% module load \emph{package}}
\end{alltt}
}
\noindent
The second major advantage is that a user can \emph{unload} previously
loaded modules, to revert changes in the environment and restore their
environment to the one before they loaded that module.  This means
that users can control their build environment by switching between
version of the same package or changing between different compilers or
mpi stacks.  These power features show why the environment module
system has widely used since the late 1990's.


%\kenneth{we also need to briefly describe \texttt{module avail} and
%\texttt{module list}, since they're used in examples; maybe we also need to briefly
%mention that the user interacts with module files via the \texttt{module} command,
%which accepts various subcommands}
%

There have been several environment module system that have been
developed over the years.  The original
implementation~\cite{furlani91} was collection of shell scripts.  At
some point this was rewritten in a TCL/C combinations~\cite{em}.

In the traditional implementation, a command named \texttt{module}
is implemented as a simple shell function (for Bourne-compatible shells) or
alias (for csh-compatible shells) which evaluates the commands printed by a
helper tool (e.g., \texttt{modulecmd}) to standard output. This helper tool
implements the actual functionality of identifying the requested command,
locating and parsing the corresponding module files, and generating the
commands necessary to modify the user's environment.

Over time, multiple implementations of the helper tool
have been developed. The most commonly used version is written in C, using the Tcl
library to parse and evaluate module files~\cite{em}. A second implementation, which
was never packaged as a release and is still marked as experimental by the
authors, is written in Tcl only~\cite{em}. For the most part, these two implementations
offer identical functionality, however, they obviously suffer from the usual
problem of keeping the different code bases consistent, which sometimes leads
to subtle effects when switching between them. In addition, there exists a
fork of the Tcl-only implementation which has been heavily adjusted to meet
the requirements of the DEISA (Distributed European Infrastructure for
Supercomputing Applications) project~\cite{wikiDEISA}.  In
1997, a completely C based implementation was made
available~\cite{cmod}.  It has not been updated since 1998.

All of the enviroment module systems have the same user interface.
The command is given by:
{\small
\begin{alltt}
    \textbf{\% module} \emph{[options]} \emph{command} ...
\end{alltt}
}
\noindent
Where \emph{command} can be \texttt{load} to load modules \texttt{unload}
to unload modules, \texttt{list} to list the loaded modules, or
\texttt{avail} to print the modules that can be currently loaded.


%\remark{briefly explain Tcl/C and Tcl-only environment module tools}

While these implementations provide the desired basic functionality, they
vary in how well maintained they are. In all cases, development
progresses slowly. For example, there has been no activity in the
(publicly accessible) version control system of the Tcl-only
implementation for about two years. That is, new features such as
improved support for organizing modules in a hierarchical way are very
unlikely to happen any time soon. In the case of the Tcl/C modules
there are active discussions on the modules-interest mailing list but
improvements are infrequent.

In 2009, a new implementation of the module system called
Lmod~\cite{taccLmod} has
been made available. It is an entirely new modules tool implemented in
Lua, providing functionality that is (mostly) compatible with the Tcl-based
implementations.  Lmod is actively developed and maintained, and has
an active and thriving community. We discuss Lmod in detail in
Section~\ref{sec:lmod}.

%\markus{From what I can see, there are at least . However, the answers from the maintainers
%suggest to me that they have no interest in changing things too much. What is
%your impression? I'm also not sure whether we should really write this down
%in a paper ;-)}

%\markus{One possible reviewer comment may be: Why didn't you contribute a patch to
%the existing project rather than reinventing the wheel? Do we have a good
%answer to this? Robert, did you actually try to contribute and they rejected
%to include the patch?}
%
%\robert{The truth was that I saw the same behaviour in
%  environment modules mailing list.  My extreme dislike of Tcl and
%  complete lack of understanding of the internals of Tcl/C modules
%  meant that I wasn't going to patch Env. Modules.   I really didn't
%  plan to take over the Env. Modules world.  I thought I'd prototype
%  this new module system, then someone who understood Tcl/C and
%  modules would convert the prototype into Tcl/C.}
%
%\robert{But it was very clear from the beginning that supporting
%  the hierarchy was going to require a major refactoring.  There has
%  to be a notion of inactive modules.  Lmod uses a table that it
%  encodes in the enviroment.  This made it easier to support inactive
%  modules, properties.}

\subsection{Module files}
\label{sec:Module_files}

In essence, module files are shell-independent textual description of
what needs to be changed in the user's environment to make a
particular software package available. Such changes may include the
adjustment of environment variables such as \texttt{\$PATH} or setting
additional package-specific variables, e.g., convenience
variables pointing to the include and/or library paths.  In addition,
module files typically include a brief one-line description of the
package displayed by \texttt{module whatis} as well as a longer help
text printed by \texttt{module help} to describe the basic usage,
where to find the package documentation, and whom to contact in case
of usage problems (this may be the site's application support team or
the developers of the package directly).

Module files are searched for in directories specified by the
environment variable \texttt{\$MODULEPATH}. The name of a module is defined
as the path to the corresponding module file in one of directories that are
part of \texttt{\$MODULEPATH}. For example, the module file located in
{\small
\begin{alltt}
    <\emph{prefix}>/GCC/4.8.2
\end{alltt}
}
provides a module for version 4.8.2 of the GNU Compiler Collection with the
name `\texttt{GCC/4.8.2}'.

\subsection{Module naming scheme}
\label{sec:Module_naming_scheme}
When the environment module system was invented sites typically had
one compiler period.  There was the system compiler and that was it.
There weren't even multiple versions of the system compiler installed
at the same time.  Now sites have multiple versions of the same
compiler and multiple compilers (e.g. GCC, Intel, Clang, PGI, ...).
While there is some interopability for pure C programs between
compilers, there is none for Fortran and C++ programs.  This means
that there has to be multiple version of libraries like the C++
libraries like Boost for each compiler and compiler version.

Moreover, since packages such as MPI implementations are inherently tied to a
particular compiler and most often even a particular version, disambiguating
module names can be a daunting task. For example, for the three compilers
shown above, the corresponding Open\,MPI modules are often named as follows:
{\small
\begin{alltt}
    OpenMPI/1.7.3-GCC-4.8.2
    OpenMPI/1.7.3-Intel-14.0
    OpenMPI/1.7.3-Clang-3.4
\end{alltt}
}

The situation is more complicated for full-blown scientific software
packages like WRF compiled with a particular compiler and linked
against a particular MPI stack, e.g.:
{\small
\begin{alltt}
    WRF/3.5-GCC-4.8.2-OpenMPI-1.7.3
    WRF/3.5-Intel-14.0-OpenMPI-1.7.3
\end{alltt}
}
\noindent
Note that such packages in many cases also depend on a set of mathematical
libraries, such as OpenBLAS+(Sca)LAPACK+FFTW vs. ACML vs. Intel MKL, which in a
real scenario extends the module name even further.

A common solution to this issue is to define so-called \emph{toolchain}
modules, packaging a compiler, an MPI library, and one or more packages
providing linear algebra and FFT functionality. For example, a \texttt{goolf}
toolchain module may combine (i.e., implicitly load modules for) GCC,
Open\,MPI, OpenBLAS, (Sca)LAPACK and FFTW---each with a well-defined version. The
first WRF module as shown above may then simply refer to a toolchain instead of the
individual packages:
{\small
\begin{alltt}
    WRF/3.5-goolf-1.6.10
\end{alltt}
}
The toolchain concept also offers the possibility to categorize modules by
toolchain, however, if a software package is available for multiple
toolchains, it will then show up in multiple sections of the \texttt{module
avail} output. The downside of using toolchains, however, is that users have
to be aware what is hidden behind the (often rather cryptic) toolchain names,
and that a toolchain version has no direct relationship with the versions of
the encapsulated packages.

\remark{the paragraph below needs to be integrated in this text}
The example above also shows one possible way to categorize modules by
placing their module files into appropriately named subdirectories (e.g.,
`\texttt{compiler}', `\texttt{mpi}', `\texttt{math}', etc.). Another common
option is to list the individual subdirectories in \texttt{\$MODULEPATH}, so
that the module names are shorter, but the modules are still nicely separated
in the output of module avail, e.g.:
{\small
\begin{alltt}
    \textbf{% module avail}
    ----- <\emph{prefix}>/compiler -----
    GCC/4.8.2   Intel/14.0  Clang/3.4
    ----- <s\emph{prefix}r>/mpi -----
    OpenMPI/1.7.3 MVAPICH/1.9
\end{alltt}
}

It should be pointed out that although all of the approaches to name and
categorize module files presented above try to improve the overall
organization of the available modules, a typical module listing on an HPC
system can still be overwhelming, as the total number of modules can easily
be in the order of several hundreds. Moreover, all traditional aproaches offer a
multitude of options for (especially novice) users to shoot themselves in the
foot, that is, to load modules which are incompatible to each other. While
module files in principle offer the possibility to specify conflicts and
thereby prevent loading of incompatible modules, all conflicting modules have
to be explicitly listed. For example, the Open\,MPI module built for GCC may
specify that it is incompatible with modules providing Intel or Clang
compilers. However, this means that these conflict specifications have to be
adjusted once an additional compiler (e.g., PGI) gets installed on the
system---which is clearly a maintenance nightmare from the perspective of a
system administrator.

This flat naming approach is common but it places burdens on users.
If a user wants an application it is straight-forward to pick one such
as WRF.  But when a developer is using multiple parallel libraries to
build their own application, he or she is required to pick matching
compiler, mpi stack and compiler dependent and parallel dependent
libraries.  When developers chooses a mismatched set of module, they
might get lucky and their application will fail to run or die
immediately.  Otherwise, their application will fail in completely
mysterous ways and can consume a great deal of system staff time
trying to resolve the failure.  Section~\ref{sec:hierarchical} show
another approach to remove this burden from users.


%\remark{main issues with module files: maintaining consistency (contents of module files, naming),
%putting the burden on users to correctly align things and not run into trouble (avoiding conflicts, etc.)}
%
%
%\remark{module naming scheme should be discussed separately from module files, different concepts,
%making the distinction is important in the paper context}

%\remark{flat naming scheme (most common?),

\subsection{Installing scientific software}
\label{sec:installing}

HPC sites around the world use a wide variety of methods and tools to
install scientific software.
\remark{refer to the results of the "Getting Scientific Software Installed BoF sessions at SC13 \& ISC14 to support the concerns mentioned in Section~\ref{sec:installing}}

\subsubsection{Manual installation}

Commonly, sites rely heavily on the manpower of (a part of)
the user support team, and simply manually install software packages following
the install guides that are either composed by themselves over time or are provided
by the respective software development teams (that is, if those are available, and
sufficiently detailed and up-to-date).

\subsubsection{Scripting}

Frequently, sites end up resorting to putting together a collection of (most
commonly bash) scripts to automate the often repititive and error-prone tasks of
configuring, building and installing the software packages, in whichever scripting
language is of preference at that time. Typically, this quickly results in a pile of
loosely coupled hard-to-maintain scripts, which are more often than not only really
understood by just a small fraction or even a single member of the user support
teams~\cite{Jim}, even though they are (heavily) relied upon. On top of this, these
scripts tend to have the site software installation policies (which are likely quite
site-specific) hard-wired into them, leaving little flexibility for other HPC
sites using a slightly different policy to reuse them as is (assuming the scripts
are made available to others).

\subsubsection{Package managers}

Yet another approach is to rely on the packaging and package managing tools used
by the operating system, e.g. RPMs and \texttt{yum} for RedHat-based systems,
\texttt{apt-get}, Debian packages for Debian-like systems, Portage for Gentoo, etc.
Package managers have more than adequate solutions for some aspects of
installing large software stacks, including dependency tracking/resolution, software
updates, uninstalling software, etc. However, they are ill-suited for dealing with
certain peculiarities that come into play when installing scientific software on
HPC systems, such as requiring multiple builds/versions of the same software package
to be installed at the same time and heavily customized install procedures involving
non-standard tools (as opposed to the
\texttt{configure} -- \texttt{make} -- \texttt{make install} paradigm commonly used
by system software). Also, the package specification formats (e.g., \texttt{.spec}
files used for generating RPMs) tend to have little support for factoring out
common patterns in install procedures, resulting in lots of copy-pasting and thus
a hard to maintain softeware and install build infrastructure.

Nevertheless, a couple of the larger HPC sites in the world
(e.g., TACC, see Section~\ref{sec:related_work}) are taking this packaging approach,
since they are able to dedicate large amounts of manpower to the task of getting
scientific software installed; this is typically infeasible for smaller HPC sites
however. Besides these concerns, the efforts spent on shoe-horning the install
procedures of scientific software into the package specifications (e.g., 
\texttt{.spec} files for generating RPMs) are unlikely to benefit other HPC sites
due to, again, little control to apply their own site-specific installation
policies without spending significant additional time to modify the packages to
their needs.

\subsubsection{Configuration management tools}

Some sites (ab)use configuration management tools like Puppet or Chef to help manage
their software installations. Since these tools are intended for entirely different
purposes this is clearly not a good approach either, yet it may possible to come up
with a pragmatic workflow, although it is unlikely that it provides an adequate
solution that is easy to use and maintain.

\subsubsection{Custom tools}

Other solutions include tools custom-made for installing scientific software
on HPC systems. We will briefly discuss a number of these in
Section~\ref{sec:related_work}. Typically, these tools were developed in-house for
a certain period of time, after having started as yet another bunch of
scripts being hacked together, up to the point where they were deemed potentially
useful for other HPC sites as well. Unfortunately, these projects typically die a
silent death as quickly as they surfaced, due to basically being a one-man project,
lack of documentation and production usage by different HPC sites (for whatever
reason), inadequate flexibility and features, etc. We discuss one notable 
exception, \easybuild{}~\cite{EasyBuildSC12}, in detail in
Section~\ref{sec:easybuild}.

\subsubsection{Creating module files}

Usually, the creation of module files remain to be handled manually since the
procedure is often deemed ``simple enough". However, this significantly impedes
maintaining a consistent set of module files, and again is likely to result in
imposing the responsibility of creating module files for software installations
on one person or, at best, a handful of people. This is obviously a major concern
on production systems w.r.t.~ensuring continuity of support for installing
scientific software for end users.

%%???
%%
%%\remark{manual, in-house scripting, 'Jim', little to no collaboration across
%%HPC sites (a few exceptions!)}
%%
%%\markus{Does it make sense to also mention RPM and DEB packages? For a
%%regular software install, the downside is that only one version can be
%%available. But of course packaging systems can be combined with our proposed
%%approach to roll out the software on a bunch of nodes (see TACC).}
%%
%%\kenneth{imho, yes, it makes sense to mention the open issues with traditional
%%packaging systems: only one version/build per software package, usually little
%%support for the mess you run into with scientific software, ...}
%%
%%\remark{issues with using packaging tools like RPM (cfr. TACC): requires tons of manpower,
%%very little flexibility for site-specific modifications, little collaboration between sites thus
%%lots of duplicate effort}

\subsection{Lack of collaboration, tools and policies}
\label{sec:traditional_lack}

Even though the problems w.r.t. installing scientific software and using
traditional module naming schemes are well recognized, there is an abundant lack
of available tools and policies that try to provide a solution to these problems.
Additionally, there has been very little collaboration between HPC sites on these
issues, despite them being a significant burden for HPC user support teams
(especially the smaller ones). Even though HPC sites around the world are facing
very similar problems in this area, lots of duplicate effort is still being done,
resulting in a tremendous waste of manpower (and hence time and money), and a loss
of oopportunities to benefit from a collaborative effort, e.g., capturing the
immensely valuable expertise that is wide spread across HPC sites worldwide.

In the remainder of this paper we present a modern alternative approach to
installing scientific software, which involves a different way of organizing
module files and using emerging appropriate tools, with the intent to resolve
these common issues.


%???
%\remark{manual creating of module files (consistency issues), repetitive \&
%error-prone work of installing scientific software, \ldots}
